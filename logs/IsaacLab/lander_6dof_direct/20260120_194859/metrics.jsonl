{"step": 0, "dataset_size": 656.0, "train_return": -17.418519973754883, "train_length": 82.0, "train_episodes": 8.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 760.0, "train_return": -131.09291076660156, "train_length": 95.0, "train_episodes": 9.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 776.0, "train_return": -52.580318450927734, "train_length": 97.0, "train_episodes": 10.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 840.0, "train_return": -82.66702270507812, "train_length": 105.0, "train_episodes": 11.0, "envs_finished": 6.0}
{"step": 0, "dataset_size": 1256.0, "train_return": -81.62777709960938, "train_length": 157.0, "train_episodes": 12.0, "envs_finished": 3.0}
{"step": 0, "dataset_size": 1312.0, "train_return": -3441.101806640625, "train_length": 164.0, "train_episodes": 13.0, "envs_finished": 2.0}
{"step": 0, "dataset_size": 1544.0, "train_return": -70.09626007080078, "train_length": 193.0, "train_episodes": 14.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 1768.0, "train_return": -4674.8017578125, "train_length": 221.0, "train_episodes": 15.0, "envs_finished": 1.0}
{"step": 0, "dataset_size": 1800.0, "train_return": -110.22364807128906, "train_length": 130.0, "train_episodes": 16.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 1808.0, "train_return": -69.16243743896484, "train_length": 129.0, "train_episodes": 17.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 2016.0, "train_return": -441.3497619628906, "train_length": 170.0, "train_episodes": 18.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 2352.0, "train_return": -187.9450225830078, "train_length": 130.0, "train_episodes": 19.0, "envs_finished": 2.0}
{"step": 0, "dataset_size": 2424.0, "train_return": -72.91439819335938, "train_length": 110.0, "train_episodes": 20.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 2640.0, "train_return": -91.9720687866211, "train_length": 109.0, "train_episodes": 21.0, "envs_finished": 1.0}
{"step": 0, "dataset_size": 2704.0, "train_return": -93.22615051269531, "train_length": 113.0, "train_episodes": 22.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 2712.0, "train_return": -118.4271469116211, "train_length": 182.0, "train_episodes": 23.0, "envs_finished": 3.0}
{"step": 0, "dataset_size": 2752.0, "train_return": -102.18254852294922, "train_length": 92.0, "train_episodes": 24.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 3208.0, "train_return": -166.78369140625, "train_length": 296.0, "train_episodes": 25.0, "envs_finished": 6.0}
{"step": 0, "dataset_size": 3312.0, "train_return": -115.59848022460938, "train_length": 120.0, "train_episodes": 26.0, "envs_finished": 2.0}
{"step": 0, "dataset_size": 3408.0, "train_return": -156.45811462402344, "train_length": 200.0, "train_episodes": 27.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 3496.0, "train_return": -65.86907196044922, "train_length": 134.0, "train_episodes": 28.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 3680.0, "train_return": -86.92453002929688, "train_length": 130.0, "train_episodes": 29.0, "envs_finished": 1.0}
{"step": 0, "dataset_size": 4000.0, "train_return": -135.4542999267578, "train_length": 156.0, "train_episodes": 30.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 4008.0, "train_return": -92.69977569580078, "train_length": 162.0, "train_episodes": 31.0, "envs_finished": 3.0}
{"step": 0, "dataset_size": 4088.0, "train_return": -979.6517944335938, "train_length": 173.0, "train_episodes": 32.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 4240.0, "train_return": -146.1686553955078, "train_length": 116.0, "train_episodes": 33.0, "envs_finished": 26.0}
{"step": 0, "dataset_size": 4240.0, "train_return": -89.03973388671875, "train_length": 129.0, "train_episodes": 33.0, "envs_finished": 26.0}
{"step": 0, "dataset_size": 4272.0, "train_return": -32.54130554199219, "train_length": 97.0, "train_episodes": 35.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 4816.0, "train_return": -127.827392578125, "train_length": 176.0, "train_episodes": 36.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 4920.0, "train_return": -133.41400146484375, "train_length": 104.0, "train_episodes": 37.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 5064.0, "train_return": -660.1421508789062, "train_length": 173.0, "train_episodes": 38.0, "envs_finished": 1.0}
{"step": 0, "dataset_size": 5072.0, "train_return": -64.63762664794922, "train_length": 100.0, "train_episodes": 39.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 5104.0, "train_return": -86.42780303955078, "train_length": 108.0, "train_episodes": 40.0, "envs_finished": 2.0}
{"step": 0, "dataset_size": 5120.0, "train_return": -218.8104248046875, "train_length": 139.0, "train_episodes": 41.0, "envs_finished": 3.0}
{"step": 0, "dataset_size": 5280.0, "train_return": -157.1586456298828, "train_length": 160.0, "train_episodes": 42.0, "envs_finished": 46.0}
{"step": 0, "dataset_size": 5280.0, "train_return": -143.81219482421875, "train_length": 130.0, "train_episodes": 42.0, "envs_finished": 46.0}
{"step": 0, "dataset_size": 6144.0, "train_return": -368.421875, "train_length": 166.0, "train_episodes": 44.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 6176.0, "train_return": -97.12347412109375, "train_length": 134.0, "train_episodes": 45.0, "envs_finished": 2.0}
{"step": 0, "dataset_size": 6216.0, "train_return": -111.74748229980469, "train_length": 162.0, "train_episodes": 46.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 6248.0, "train_return": -439.593505859375, "train_length": 141.0, "train_episodes": 47.0, "envs_finished": 3.0}
{"step": 0, "dataset_size": 6400.0, "train_return": -86.45863342285156, "train_length": 140.0, "train_episodes": 48.0, "envs_finished": 6.0}
{"step": 0, "dataset_size": 6552.0, "train_return": -7.783589839935303, "train_length": 51.0, "train_episodes": 49.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 6688.0, "train_return": -1735.45849609375, "train_length": 176.0, "train_episodes": 50.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 6728.0, "train_return": -675.6078491210938, "train_length": 207.0, "train_episodes": 51.0, "envs_finished": 7.0}
{"step": 0, "dataset_size": 7024.0, "train_return": -133.00938415527344, "train_length": 101.0, "train_episodes": 52.0, "envs_finished": 5.0}
{"step": 0, "dataset_size": 7144.0, "train_return": -46.117034912109375, "train_length": 74.0, "train_episodes": 53.0, "envs_finished": 8.0}
{"step": 0, "dataset_size": 7432.0, "train_return": -62.44606018066406, "train_length": 129.0, "train_episodes": 54.0, "envs_finished": 6.0}
{"step": 0, "dataset_size": 7712.0, "train_return": -285.5280456542969, "train_length": 183.0, "train_episodes": 55.0, "envs_finished": 37.0}
{"step": 0, "dataset_size": 7712.0, "train_return": -78.66271209716797, "train_length": 123.0, "train_episodes": 55.0, "envs_finished": 37.0}
{"step": 0, "dataset_size": 7768.0, "train_return": -76.73015594482422, "train_length": 135.0, "train_episodes": 57.0, "envs_finished": 4.0}
{"step": 0, "dataset_size": 7856.0, "train_return": -125.66687774658203, "train_length": 349.0, "train_episodes": 58.0, "envs_finished": 1.0}
{"step": 16000}
{"step": 16000, "model_loss": 15.171180725097656, "model_grad_norm": Infinity, "state_loss": 9.261502265930176, "reward_loss": 3.487011671066284, "cont_loss": 0.06841196864843369, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999998, "dyn_loss": 3.923753261566162, "rep_loss": 3.923753261566162, "kl": 3.9235873222351074, "prior_ent": 109.03387451171875, "post_ent": 105.9486312866211, "normed_target_mean": -1.0282970666885376, "normed_target_std": 0.7926322817802429, "normed_target_min": -2.2140376567840576, "normed_target_max": 0.4049522280693054, "EMA_005": -1.1976265907287598, "EMA_095": -0.138763889670372, "value_mean": -0.0999966710805893, "value_std": 0.00010772948735393584, "value_min": -0.10026772320270538, "value_max": -0.09838326275348663, "target_mean": -2.486476182937622, "target_std": 1.096229910850525, "target_min": -4.126821517944336, "target_max": -0.503233790397644, "imag_reward_mean": -0.4058147072792053, "imag_reward_std": 0.00013205190771259367, "imag_reward_min": -0.4062821865081787, "imag_reward_max": -0.4051486551761627, "imag_action_mean": -0.356201171875, "imag_action_std": 0.677734375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 8.093314170837402, "actor_loss": 1.6558421850204468, "actor_grad_norm": 0.021076438948512077, "value_loss": 8.147134780883789, "value_grad_norm": Infinity, "update_count": 100.0, "fps": 0}
